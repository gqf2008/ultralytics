/// æ£€æµ‹å™¨ (Detector)
/// èŒè´£: è®¢é˜…DecodedFrame â†’ YOLOæ£€æµ‹ â†’ è¿½è¸ª â†’ å‘é€DetectionResultæ¶ˆæ¯
use crate::fastestv2::{FastestV2Config, FastestV2Postprocessor};
use crate::rtsp::DecodedFrame;
use crate::rtsp::{tracker::PersonTracker, types, TrackerType};
use crate::xbus;
use crate::{Args as YoloArgs, YOLOTask, YOLOv8};
use crossbeam_channel::{self, Receiver, Sender};
use image::{imageops, DynamicImage, ImageBuffer, RgbImage, Rgba};
use std::sync::{Arc, Mutex};
use std::time::Instant;

/// æ£€æµ‹ç»“æœ (æ£€æµ‹æ¨¡å— â†’ æ¸²æŸ“æ¨¡å—)
#[derive(Clone, Debug)]
pub struct DetectionResult {
    pub bboxes: Vec<types::BBox>,
    pub keypoints: Vec<types::PoseKeypoints>,
    pub inference_fps: f64,
    pub inference_ms: f64,
}

pub struct Detector {
    detect_model_path: String,
    pose_model_path: String,
    tracker_type: TrackerType,
    inf_size: u32,

    // ç»Ÿè®¡
    count: u64,
    last: Instant,
    current_fps: f64,

    // å§¿æ€ä¼°è®¡ä¼˜åŒ–: è·³å¸§ç­–ç•¥
    pose_skip_counter: u32,
    pose_skip_interval: u32, // æ¯Nå¸§åšä¸€æ¬¡å§¿æ€ä¼°è®¡

    // è¿½è¸ªå™¨
    tracker: Option<PersonTracker>,
}

impl Detector {
    pub fn new(
        detect_model: String,
        pose_model: String,
        tracker_type: TrackerType,
        inf_size: u32,
    ) -> Self {
        Self {
            detect_model_path: detect_model,
            pose_model_path: pose_model,
            tracker_type,
            inf_size,
            count: 0,
            last: Instant::now(),
            current_fps: 0.0,
            pose_skip_counter: 0,
            pose_skip_interval: 5, // æ¯5å¸§åšä¸€æ¬¡å§¿æ€ä¼°è®¡,æå‡æ€§èƒ½
            tracker: None,         // å»¶è¿Ÿåˆå§‹åŒ–,åœ¨runä¸­åˆ›å»º
        }
    }

    pub fn run(&mut self) {
        println!("ğŸ” æ£€æµ‹æ¨¡å—å¯åŠ¨");

        let is_fastestv2 = self.detect_model_path.contains("fastestv2");

        // åŠ è½½æ£€æµ‹æ¨¡å‹
        let detect_args = YoloArgs {
            model: self.detect_model_path.clone(),
            width: Some(self.inf_size),
            height: Some(self.inf_size),
            conf: if is_fastestv2 { 0.10 } else { 0.15 },
            iou: 0.45,
            source: String::new(),
            device_id: 0,
            trt: false,
            cuda: false,
            batch: 1,
            batch_min: 1,
            batch_max: 1,
            fp16: false,
            task: Some(YOLOTask::Detect),
            nc: None,
            nk: None,
            nm: None,
            kconf: 0.55,
            profile: false,
        };

        let detect_model = match YOLOv8::new(detect_args) {
            Ok(m) => {
                println!("âœ… æ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ");
                Arc::new(Mutex::new(m))
            }
            Err(e) => {
                eprintln!("âŒ æ£€æµ‹æ¨¡å‹åŠ è½½å¤±è´¥: {}", e);
                return;
            }
        };

        // FastestV2ä¸“ç”¨åå¤„ç†
        let fastestv2_postprocessor = if is_fastestv2 {
            let config = FastestV2Config {
                conf_threshold: 0.05, // FastestV2è¾“å‡ºç½®ä¿¡åº¦è¾ƒä½,ä½¿ç”¨0.05é˜ˆå€¼
                iou_threshold: 0.45,
                num_classes: 80,          // COCO ç±»åˆ«æ•°
                num_anchors: 3,           // æ¯ä¸ªå°ºåº¦3ä¸ªanchor
                strides: vec![8, 16, 32], // YOLOv8é»˜è®¤stride
                anchors: vec![
                    12.64, 19.39, 37.88, 51.48, 55.71, 138.31, 79.57, 257.11, 140.63, 149.70,
                    279.92, 258.87,
                ],
            };
            Some(FastestV2Postprocessor::new(
                config,
                self.inf_size as usize,
                self.inf_size as usize,
            ))
        } else {
            None
        };

        // åŠ è½½å§¿æ€æ¨¡å‹ (å¯é€‰)
        let pose_model = if !self.pose_model_path.is_empty() {
            let pose_args = YoloArgs {
                model: self.pose_model_path.clone(),
                width: Some(self.inf_size),
                height: Some(self.inf_size),
                conf: 0.5,
                iou: 0.45,
                kconf: 0.55,
                source: String::new(),
                device_id: 0,
                trt: false,
                cuda: false,
                batch: 1,
                batch_min: 1,
                batch_max: 1,
                fp16: false,
                task: Some(YOLOTask::Pose),
                nc: None,
                nk: Some(17),
                nm: None,
                profile: false,
            };

            match YOLOv8::new(pose_args) {
                Ok(m) => {
                    println!("âœ… å§¿æ€æ¨¡å‹åŠ è½½æˆåŠŸ");
                    Some(Arc::new(Mutex::new(m)))
                }
                Err(e) => {
                    println!("âš ï¸  å§¿æ€æ¨¡å‹åŠ è½½å¤±è´¥: {}", e);
                    None
                }
            }
        } else {
            None
        };

        // è®¢é˜…è§£ç å¸§ - ä»…å°†ä»»åŠ¡æ”¾å…¥é˜Ÿåˆ—
        let inf_size = self.inf_size;
        let (tx, rx): (Sender<DecodedFrame>, Receiver<DecodedFrame>) =
            crossbeam_channel::bounded(120);

        let _sub = xbus::subscribe::<DecodedFrame, _>(move |frame| {
            // è½»é‡çº§æ“ä½œï¼šä»…å°†å¸§æ”¾å…¥å·¥ä½œé˜Ÿåˆ—
            if let Err(_) = tx.try_send(frame.clone()) {
                //eprintln!("âŒ ç›®æ ‡æ£€æµ‹é˜Ÿåˆ—å‘é€å¤±è´¥: {}", e);
            }
        });

        println!("âœ… æ£€æµ‹æ¨¡å—å·²è®¢é˜…DecodedFrame,ç­‰å¾…æ•°æ®...");

        // åˆå§‹åŒ–è¿½è¸ªå™¨
        self.tracker = Some(PersonTracker::new());
        println!(
            "âœ… è¿½è¸ªå™¨åˆå§‹åŒ–æˆåŠŸ ({})",
            match self.tracker_type {
                TrackerType::DeepSort => "DeepSort",
                TrackerType::ByteTrack => "ByteTrack",
            }
        );

        // å·¥ä½œçº¿ç¨‹:å¼‚æ­¥å¤„ç†æ£€æµ‹ä»»åŠ¡
        loop {
            match rx.recv() {
                Ok(frame) => {
                    self.process_frame(
                        frame,
                        &detect_model,
                        &pose_model,
                        &fastestv2_postprocessor,
                        inf_size,
                    );
                }
                Err(e) => {
                    eprintln!("âŒ ç›®æ ‡æ£€æµ‹é˜Ÿåˆ—æ¥æ”¶å¤±è´¥: {}", e);
                    break;
                }
            }

            // TODO: ç›‘å¬SystemControlæ¶ˆæ¯,æ”¯æŒä¼˜é›…é€€å‡º
        }
    }

    /// å¤„ç†å•å¸§æ£€æµ‹ (åœ¨å·¥ä½œçº¿ç¨‹ä¸­æ‰§è¡Œ)
    fn process_frame(
        &mut self,
        frame: DecodedFrame,
        detect_model: &Arc<Mutex<YOLOv8>>,
        pose_model: &Option<Arc<Mutex<YOLOv8>>>,
        fastestv2_postprocessor: &Option<FastestV2Postprocessor>,
        inf_size: u32,
    ) {
        let start = Instant::now();

        // 1. RGBA â†’ RgbaImage
        let rgba_img = match ImageBuffer::<Rgba<u8>, _>::from_raw(
            frame.width,
            frame.height,
            frame.rgba_data,
        ) {
            Some(img) => img,
            None => {
                eprintln!("âŒ RGBAå›¾åƒè½¬æ¢å¤±è´¥");
                return;
            }
        };
        // 2. Resize: åŠ¨æ€åˆ†è¾¨ç‡ â†’ 320x320
        let resized_rgba = imageops::resize(
            &rgba_img,
            inf_size,
            inf_size,
            imageops::FilterType::Triangle,
        );

        // 3. RGBA â†’ RGB
        let rgb_data: Vec<u8> = resized_rgba
            .pixels()
            .flat_map(|p| vec![p.0[0], p.0[1], p.0[2]])
            .collect();

        // 4. RGB â†’ DynamicImage
        let rgb_img = match RgbImage::from_raw(inf_size, inf_size, rgb_data) {
            Some(img) => img,
            None => {
                eprintln!("âŒ RGBå›¾åƒè½¬æ¢å¤±è´¥");
                return;
            }
        };
        let img = DynamicImage::ImageRgb8(rgb_img);

        // 5. YOLOæ£€æµ‹
        let detect_results = if let Some(ref pp) = fastestv2_postprocessor {
            // FastestV2ä¸“ç”¨åå¤„ç†
            let mut model = detect_model.lock().unwrap();
            let xs = model.preprocess(&vec![img.clone()]).unwrap_or_default();
            let ys = model.engine_mut().run(xs, false).unwrap_or_default();
            drop(model);
            pp.postprocess(ys, &vec![img.clone()]).unwrap_or_default()
        } else {
            let mut model = detect_model.lock().unwrap();
            model.run(&vec![img.clone()]).unwrap_or_default()
        };

        // 6. æå–æ£€æµ‹æ¡†å¹¶ç¼©æ”¾åˆ°åŸå§‹åˆ†è¾¨ç‡
        let scale_x = frame.width as f32 / inf_size as f32;
        let scale_y = frame.height as f32 / inf_size as f32;

        let mut bboxes = Vec::new();
        let mut all_detections_count = 0; // è°ƒè¯•: ç»Ÿè®¡æ‰€æœ‰ç±»åˆ«çš„æ£€æµ‹æ•°
        let mut person_detections_count = 0; // è°ƒè¯•: ç»Ÿè®¡äººçš„æ£€æµ‹æ•°

        // COCOç±»åˆ«: 0=person, 39=bottle, 41=cup, 56=chair, 62=tv, 63=laptop, 73=book, 76=scissors
        const DETECT_CLASSES: &[usize] = &[0]; // åªæ£€æµ‹äºº,å¦‚éœ€æ£€æµ‹å…¶ä»–ç±»åˆ«å¯æ·»åŠ : &[0, 39, 41, 56, 62, 63, 73, 76]

        for result in &detect_results {
            if let Some(boxes) = result.bboxes() {
                all_detections_count += boxes.len();
                for bbox in boxes {
                    // æ£€æµ‹æŒ‡å®šç±»åˆ«
                    if DETECT_CLASSES.contains(&bbox.id()) {
                        if bbox.id() == 0 {
                            person_detections_count += 1;
                        }
                        if bbox.confidence() >= 0.05 {
                            bboxes.push(types::BBox {
                                x1: bbox.xmin() * scale_x,
                                y1: bbox.ymin() * scale_y,
                                x2: bbox.xmax() * scale_x,
                                y2: bbox.ymax() * scale_y,
                                confidence: bbox.confidence(),
                                class_id: bbox.id() as u32,
                            });
                        } else if self.count % 30 == 0 && bbox.id() == 0 {
                            eprintln!("âš ï¸ ä½ç½®ä¿¡åº¦äººæ£€æµ‹: conf={:.3}", bbox.confidence());
                        }
                    }
                }
            }
        }

        // è°ƒè¯•æ—¥å¿— - ç»Ÿè®¡å„ç±»åˆ«åˆ†å¸ƒ
        if self.count % 30 == 0 && all_detections_count > 0 {
            use std::collections::HashMap;
            let mut class_counts: HashMap<usize, usize> = HashMap::new();
            for result in &detect_results {
                if let Some(boxes) = result.bboxes() {
                    for bbox in boxes {
                        *class_counts.entry(bbox.id()).or_insert(0) += 1;
                    }
                }
            }
            let mut sorted: Vec<_> = class_counts.iter().collect();
            sorted.sort_by(|a, b| b.1.cmp(a.1));
            let top3: Vec<String> = sorted
                .iter()
                .take(3)
                .map(|(k, v)| format!("c{}:{}", k, v))
                .collect();
            eprintln!(
                "ğŸ” åŸå§‹æ£€æµ‹: æ€»{}ä¸ª (top3: {}) | äºº{}ä¸ª | é€šè¿‡é˜ˆå€¼{}ä¸ª",
                all_detections_count,
                top3.join(" "),
                person_detections_count,
                bboxes.len()
            );
        }

        // 7. å§¿æ€ä¼°è®¡ (å¯é€‰,æ€§èƒ½ä¼˜å…ˆ - è·³å¸§ç­–ç•¥)
        let mut keypoints = Vec::new();
        if let Some(pose_model) = pose_model {
            // è·³å¸§ä¼˜åŒ–: æ¯Nå¸§æ‰åšä¸€æ¬¡å§¿æ€ä¼°è®¡
            self.pose_skip_counter += 1;
            let should_run_pose = self.pose_skip_counter >= self.pose_skip_interval;
            if should_run_pose {
                self.pose_skip_counter = 0;
            }

            // é™åˆ¶å§¿æ€ä¼°è®¡æ•°é‡,é¿å…æ€§èƒ½ä¸‹é™ (åªå¯¹ç¬¬1ä¸ªäººåšå§¿æ€ä¼°è®¡)
            let max_pose_detections = 1;
            let bboxes_for_pose: Vec<_> = bboxes.iter().take(max_pose_detections).collect();

            if should_run_pose && !bboxes_for_pose.is_empty() {
                if let Ok(mut model) = pose_model.lock() {
                    // å¯¹æ¯ä¸ªäººä½“è¾¹ç•Œæ¡†è¿è¡Œå§¿æ€ä¼°è®¡ (bboxå·²ç¼©æ”¾åˆ°åŸå§‹åˆ†è¾¨ç‡)
                    for bbox in bboxes_for_pose {
                        // è£å‰ªè¾¹ç•Œæ¡†åŒºåŸŸ (å¸¦padding)
                        let padding = 20.0;
                        let x1 = (bbox.x1 - padding).max(0.0) as u32;
                        let y1 = (bbox.y1 - padding).max(0.0) as u32;
                        let x2 = (bbox.x2 + padding).min(frame.width as f32) as u32;
                        let y2 = (bbox.y2 + padding).min(frame.height as f32) as u32;

                        let crop_w = x2.saturating_sub(x1);
                        let crop_h = y2.saturating_sub(y1);

                        // éªŒè¯è£å‰ªåŒºåŸŸæœ‰æ•ˆæ€§
                        if crop_w < 10 || crop_h < 10 {
                            continue;
                        }

                        // åˆ›å»ºè£å‰ªåŒºåŸŸçš„å­å›¾åƒ
                        let cropped_img =
                            imageops::crop_imm(&rgba_img, x1, y1, crop_w, crop_h).to_image();
                        let dynamic_img = DynamicImage::ImageRgba8(cropped_img);

                        // è¿è¡Œå§¿æ€ä¼°è®¡
                        if let Ok(pose_results) = model.run(&vec![dynamic_img]) {
                            for result in &pose_results {
                                if let Some(kpts_batch) = result.keypoints() {
                                    for kpts_person in kpts_batch {
                                        let mut points = Vec::new();
                                        for kp in kpts_person.iter() {
                                            // è½¬æ¢åæ ‡åˆ°åŸå›¾
                                            points.push((
                                                kp.x() + x1 as f32,
                                                kp.y() + y1 as f32,
                                                kp.confidence(),
                                            ));
                                        }
                                        if !points.is_empty() {
                                            keypoints.push(types::PoseKeypoints { points });
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }

        // 8. è¿½è¸ªå™¨æ›´æ–° (ä½¿ç”¨æ£€æµ‹ç»“æœå’Œå§¿æ€å…³é”®ç‚¹)
        if let Some(ref mut tracker) = self.tracker {
            // å‡†å¤‡RGBAå¸§æ•°æ®ç”¨äºç‰¹å¾æå–
            let frame_rgba = Some((rgba_img.as_raw().as_slice(), frame.width, frame.height));

            // æ›´æ–°è¿½è¸ªå™¨,è·å–å¸¦IDçš„è¿½è¸ªå¯¹è±¡
            let tracked_persons = tracker.update(&bboxes, &keypoints, frame_rgba);

            // ç”¨è¿½è¸ªç»“æœæ›¿æ¢åŸå§‹æ£€æµ‹æ¡† (ç°åœ¨bboxæœ‰ç¨³å®šIDäº†)
            let original_keypoints = keypoints.clone(); // ä¿ç•™åŸå§‹å…³é”®ç‚¹
            bboxes.clear();
            keypoints.clear();

            for (idx, person) in tracked_persons.iter().enumerate() {
                // æ˜¾ç¤ºæ‰€æœ‰è½¨è¿¹ (åŒ…æ‹¬æœªç¡®è®¤çš„,è°ƒè¯•ç”¨)
                // TODO: æ¢å¤ä¸º if person.confirmed åªæ˜¾ç¤ºç¨³å®šè½¨è¿¹
                if true || person.confirmed {
                    bboxes.push(types::BBox {
                        x1: person.bbox.x1,
                        y1: person.bbox.y1,
                        x2: person.bbox.x2,
                        y2: person.bbox.y2,
                        confidence: person.bbox.confidence,
                        class_id: person.id, // ä½¿ç”¨è¿½è¸ªID
                    });

                    // å¦‚æœæœ‰å¯¹åº”çš„å§¿æ€å…³é”®ç‚¹,ä¹Ÿæ·»åŠ è¿›å»
                    if idx < original_keypoints.len() {
                        keypoints.push(original_keypoints[idx].clone());
                    }
                }
            }
        }

        // 9. æ›´æ–°ç»Ÿè®¡
        self.count += 1;
        let now = Instant::now();
        if now.duration_since(self.last).as_secs() >= 1 {
            self.current_fps = self.count as f64 / now.duration_since(self.last).as_secs_f64();
            self.count = 0;
            self.last = now;
        }

        let inference_ms = start.elapsed().as_secs_f64() * 1000.0;

        // è°ƒè¯•æ—¥å¿— (æ¯ç§’æ‰“å°ä¸€æ¬¡)
        if self.count % 30 == 0 {
            eprintln!(
                "ğŸ¯ æ£€æµ‹: {}äºº | {}å…³é”®ç‚¹ç»„ | {:.1}ms | {:.1}fps",
                bboxes.len(),
                keypoints.len(),
                inference_ms,
                self.current_fps
            );
        }

        // 9. å‘é€æ£€æµ‹ç»“æœåˆ°XBus
        xbus::post(DetectionResult {
            bboxes,
            keypoints,
            inference_fps: self.current_fps,
            inference_ms,
        });
    }
}
