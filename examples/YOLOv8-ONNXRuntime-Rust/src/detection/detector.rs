//! æ£€æµ‹å™¨ (Detector)
//! èŒè´£: è®¢é˜…DecodedFrame â†’ YOLOæ£€æµ‹ â†’ å‘é€DetectionResultæ¶ˆæ¯

use std::sync::{Arc, Mutex};
use std::time::Instant;

use crossbeam_channel::{Receiver, Sender};
use fast_image_resize as fr;
use image::{DynamicImage, ImageBuffer, RgbImage, Rgba};

use super::types::DecodedFrame;
use super::{ByteTracker, PersonTracker};
use crate::detection::types::{self, ControlMessage};
use crate::models::{FastestV2, Model, ModelType, NanoDet, YOLOv10, YOLOv11, YOLOv8, YOLOX};
use crate::{xbus, Args, YOLOTask};

#[cfg(feature = "gpu")]
use crate::utils::affine_transform::{AffineMatrix, BorderMode, InterpolationMethod};
#[cfg(feature = "gpu")]
use crate::utils::affine_transform_wgpu::WgpuAffineTransform;

/// æ£€æµ‹ç»“æœ (æ£€æµ‹æ¨¡å— â†’ æ¸²æŸ“æ¨¡å—)
#[derive(Clone, Debug)]
pub struct DetectionResult {
    pub bboxes: Vec<types::BBox>,
    pub keypoints: Vec<types::PoseKeypoints>,
    pub inference_fps: f64,
    pub inference_ms: f64,
    pub tracker_fps: f64,               // è¿½è¸ªå™¨FPS
    pub tracker_ms: f64,                // è¿½è¸ªå™¨è€—æ—¶
    pub resized_image: Option<Vec<u8>>, // Resizeåçš„RGBå›¾åƒæ•°æ® (ç”¨äºå³ä¸‹è§’æ˜¾ç¤º)
    pub resized_size: u32,              // Resizeåçš„å›¾åƒå°ºå¯¸
    pub reid_features: Vec<Vec<f32>>,   // æ¯ä¸ªbboxå¯¹åº”çš„ReIDç‰¹å¾å‘é‡
}

/// è·Ÿè¸ªå™¨ç±»å‹
enum TrackerType {
    DeepSort(PersonTracker),
    ByteTrack(ByteTracker),
    None,
}

pub struct Detector {
    detect_model_path: String,
    inf_size: u32,
    tracker: TrackerType,
    pose_enabled: bool,
    detection_enabled: bool,
    config_rx: Option<Receiver<ControlMessage>>,

    // Resizeä¼˜åŒ–: é¢„è®¡ç®—çš„æ˜ å°„è¡¨
    resize_x_map: Vec<usize>,
    resize_y_map: Vec<usize>,
    src_width: usize,
    src_height: usize,

    // GPUåŠ é€Ÿæ”¯æŒ
    #[cfg(feature = "gpu")]
    gpu_transform: Option<WgpuAffineTransform>,

    // ç»Ÿè®¡
    count: u64,
    last: Instant,
    current_fps: f64,

    // è·Ÿè¸ªç»Ÿè®¡
    tracker_count: u64,
    tracker_last: Instant,
    tracker_current_fps: f64,
}
impl Detector {
    pub fn new(
        detect_model: String,
        inf_size: u32,
        tracker_name: String,
        pose_enabled: bool,
    ) -> Self {
        // æ ¹æ®è·Ÿè¸ªå™¨åç§°åˆå§‹åŒ–
        let tracker = match tracker_name.to_lowercase().as_str() {
            "deepsort" => {
                println!("ğŸ¯ è·Ÿè¸ªå™¨: DeepSort (çº§è”åŒ¹é… + å¤–è§‚ç‰¹å¾)");
                TrackerType::DeepSort(PersonTracker::new())
            }
            "bytetrack" => {
                println!("ğŸ¯ è·Ÿè¸ªå™¨: ByteTrack (é«˜ä½åˆ†åˆ†å¼€å¤„ç†)");
                TrackerType::ByteTrack(ByteTracker::new())
            }
            _ => {
                println!("ğŸ¯ è·Ÿè¸ªå™¨: ç¦ç”¨");
                TrackerType::None
            }
        };

        Self {
            detect_model_path: detect_model,
            inf_size,
            tracker,
            pose_enabled,
            detection_enabled: true,
            config_rx: None,
            // åˆå§‹åŒ–ä¸ºç©ºæ˜ å°„è¡¨,é¦–å¸§æ—¶æ›´æ–°
            resize_x_map: Vec::new(),
            resize_y_map: Vec::new(),
            src_width: 0,
            src_height: 0,
            // å°è¯•åˆå§‹åŒ–GPUåŠ é€Ÿ
            #[cfg(feature = "gpu")]
            gpu_transform: WgpuAffineTransform::new().ok(),
            count: 0,
            last: Instant::now(),
            current_fps: 0.0,
            tracker_count: 0,
            tracker_last: Instant::now(),
            tracker_current_fps: 0.0,
        }
    }

    /// CPUå¹¶è¡Œresize (RGBA â†’ RGB + ç¼©æ”¾)
    fn cpu_resize_rgba_to_rgb(
        src_buffer: &[u8],
        src_w: usize,
        src_h: usize,
        dst_size: usize,
        x_map: &mut Vec<usize>,
        y_map: &mut Vec<usize>,
        cached_w: &mut usize,
        cached_h: &mut usize,
    ) -> Vec<u8> {
        use rayon::prelude::*;

        // ä»…åœ¨åˆ†è¾¨ç‡å˜åŒ–æ—¶é‡æ–°è®¡ç®—æ˜ å°„è¡¨
        if *cached_w != src_w || *cached_h != src_h {
            let scale_x = src_w as f32 / dst_size as f32;
            let scale_y = src_h as f32 / dst_size as f32;

            *x_map = (0..dst_size)
                .map(|x| ((x as f32 * scale_x) as usize).min(src_w - 1))
                .collect();
            *y_map = (0..dst_size)
                .map(|y| ((y as f32 * scale_y) as usize).min(src_h - 1))
                .collect();
            *cached_w = src_w;
            *cached_h = src_h;
            eprintln!(
                "ğŸ“ CPU Resizeæ˜ å°„è¡¨å·²æ›´æ–°: {}x{} â†’ {}",
                src_w, src_h, dst_size
            );
        }

        // é¢„åˆ†é…è¾“å‡º
        let mut rgb_data = vec![0u8; dst_size * dst_size * 3];

        // å¹¶è¡Œå¤„ç†æ¯ä¸€è¡Œ - æè‡´ä¼˜åŒ–ç‰ˆæœ¬
        rgb_data
            .par_chunks_exact_mut(dst_size * 3)
            .enumerate()
            .for_each(|(y, row_chunk)| {
                let src_y = y_map[y];
                let src_row_base = src_y * src_w * 4;

                // æ‰‹åŠ¨å±•å¼€å¾ªç¯ + é¿å…è¾¹ç•Œæ£€æŸ¥
                let mut out_idx = 0;
                for &src_x in x_map.iter() {
                    let src_idx = src_row_base + src_x * 4;
                    unsafe {
                        // ä½¿ç”¨unsafeé¿å…è¾¹ç•Œæ£€æŸ¥ (æ˜ å°„è¡¨å·²ä¿è¯å®‰å…¨)
                        *row_chunk.get_unchecked_mut(out_idx) = *src_buffer.get_unchecked(src_idx);
                        *row_chunk.get_unchecked_mut(out_idx + 1) =
                            *src_buffer.get_unchecked(src_idx + 1);
                        *row_chunk.get_unchecked_mut(out_idx + 2) =
                            *src_buffer.get_unchecked(src_idx + 2);
                    }
                    out_idx += 3;
                }
            });

        rgb_data
    }

    pub fn set_config_receiver(&mut self, rx: Receiver<ControlMessage>) {
        self.config_rx = Some(rx);
    }

    fn load_model(&self, model_path: &str) -> Option<Arc<Mutex<Box<dyn Model>>>> {
        // è¯†åˆ«æ¨¡å‹ç±»å‹
        let model_type = ModelType::from_path(model_path);

        // åŠ è½½æ£€æµ‹æ¨¡å‹
        let detect_args = Args {
            model: model_path.to_string(),
            width: Some(self.inf_size),
            height: Some(self.inf_size),
            conf: model_type.default_conf_threshold(),
            iou: model_type.default_iou_threshold(),
            source: String::new(),
            device_id: 0,
            trt: false,
            cuda: false,
            batch: 1,
            batch_min: 1,
            batch_max: 1,
            fp16: false,
            task: Some(YOLOTask::Detect),
            nc: None,
            nk: None,
            nm: None,
            kconf: 0.55,
            profile: false,
        };

        match model_type {
            ModelType::YOLOv8 | ModelType::YOLOv5 => match YOLOv8::new(detect_args) {
                Ok(m) => {
                    println!("âœ… YOLOv8/v5 æ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ: {}", model_path);
                    Some(Arc::new(Mutex::new(Box::new(m))))
                }
                Err(e) => {
                    eprintln!("âŒ YOLOv8/v5 æ¨¡å‹åŠ è½½å¤±è´¥: {}", e);
                    None
                }
            },
            ModelType::FastestV2 => match FastestV2::new(detect_args) {
                Ok(m) => {
                    println!("âœ… YOLO-FastestV2 æ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ");
                    Some(Arc::new(Mutex::new(Box::new(m))))
                }
                Err(e) => {
                    eprintln!("âŒ FastestV2 æ¨¡å‹åŠ è½½å¤±è´¥: {}", e);
                    None
                }
            },
            ModelType::NanoDet => match NanoDet::new(detect_args) {
                Ok(m) => {
                    println!("âœ… NanoDet æ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ");
                    Some(Arc::new(Mutex::new(Box::new(m))))
                }
                Err(e) => {
                    eprintln!("âŒ NanoDet æ¨¡å‹åŠ è½½å¤±è´¥: {}", e);
                    None
                }
            },
            ModelType::YOLOv10 => match YOLOv10::new(detect_args) {
                Ok(m) => {
                    println!("âœ… YOLOv10 æ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ");
                    Some(Arc::new(Mutex::new(Box::new(m))))
                }
                Err(e) => {
                    eprintln!("âŒ YOLOv10 æ¨¡å‹åŠ è½½å¤±è´¥: {}", e);
                    None
                }
            },
            ModelType::YOLOv11 => match YOLOv11::new(detect_args) {
                Ok(m) => {
                    println!("âœ… YOLOv11 æ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ");
                    Some(Arc::new(Mutex::new(Box::new(m))))
                }
                Err(e) => {
                    eprintln!("âŒ YOLOv11 æ¨¡å‹åŠ è½½å¤±è´¥: {}", e);
                    None
                }
            },
            ModelType::YOLOX => match YOLOX::new(detect_args) {
                Ok(m) => {
                    println!("âœ… YOLOX æ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ");
                    Some(Arc::new(Mutex::new(Box::new(m))))
                }
                Err(e) => {
                    eprintln!("âŒ YOLOX æ¨¡å‹åŠ è½½å¤±è´¥: {}", e);
                    None
                }
            },
        }
    }

    pub fn run(&mut self) {
        println!("ğŸ” æ£€æµ‹æ¨¡å—å¯åŠ¨");

        // å»¶è¿ŸåŠ è½½æ¨¡å‹ - ç­‰å¾…ç¬¬ä¸€å¸§æ•°æ®æ—¶æ‰åŠ è½½
        let mut detect_model: Option<Arc<Mutex<Box<dyn Model>>>> = None;
        let mut model_loaded = false;

        // è®¢é˜…è§£ç å¸§ - ä»…å°†ä»»åŠ¡æ”¾å…¥é˜Ÿåˆ—
        let inf_size = self.inf_size;
        // è¿›ä¸€æ­¥å‡å°é˜Ÿåˆ—é•¿åº¦ä»¥é™ä½å†…å­˜å ç”¨ (5 -> 2)
        // ç‰ºç‰²å°‘é‡å»¶è¿Ÿç¨³å®šæ€§æ¢å–æ›´ä½çš„å†…å­˜å ç”¨
        let (tx, rx): (Sender<DecodedFrame>, Receiver<DecodedFrame>) =
            crossbeam_channel::bounded(2);

        let _sub = xbus::subscribe::<DecodedFrame, _>(move |frame| {
            // è½»é‡çº§æ“ä½œï¼šä»…å°†å¸§æ”¾å…¥å·¥ä½œé˜Ÿåˆ—
            if let Err(_) = tx.try_send(frame.clone()) {
                //eprintln!("âŒ ç›®æ ‡æ£€æµ‹é˜Ÿåˆ—å‘é€å¤±è´¥: {}", e);
            }
        });

        println!("âœ… æ£€æµ‹æ¨¡å—å·²è®¢é˜…DecodedFrame,ç­‰å¾…è§†é¢‘æµå¯åŠ¨...");

        // å·¥ä½œçº¿ç¨‹: å¼‚æ­¥å¤„ç†æ£€æµ‹ä»»åŠ¡
        loop {
            // æ£€æŸ¥é…ç½®æ›´æ–°
            if let Some(rx) = &self.config_rx {
                while let Ok(msg) = rx.try_recv() {
                    match msg {
                        ControlMessage::UpdateParams {
                            conf_threshold,
                            iou_threshold,
                        } => {
                            if let Some(ref model) = detect_model {
                                let mut m = model.lock().unwrap();
                                m.set_conf(conf_threshold);
                                m.set_iou(iou_threshold);
                            }
                        }
                        ControlMessage::SwitchModel(model_path) => {
                            println!("ğŸ”„ æ­£åœ¨åˆ‡æ¢æ¨¡å‹: {}", model_path);
                            if let Some(new_model) = self.load_model(&model_path) {
                                detect_model = Some(new_model);
                                self.detect_model_path = model_path.clone();
                                model_loaded = true;

                                // é‡æ–°æ£€æŸ¥å§¿æ€ä¼°è®¡æ”¯æŒ
                                let m = detect_model.as_ref().unwrap().lock().unwrap();
                                if self.pose_enabled && !m.supports_task(YOLOTask::Pose) {
                                    println!("âš ï¸ æ–°æ¨¡å‹ä¸æ”¯æŒå§¿æ€ä¼°è®¡,å·²è‡ªåŠ¨ç¦ç”¨");
                                    self.pose_enabled = false;
                                }
                            }
                        }
                        ControlMessage::SwitchTracker(tracker_name) => {
                            println!("ğŸ”„ æ­£åœ¨åˆ‡æ¢è·Ÿè¸ªå™¨: {}", tracker_name);
                            self.tracker = match tracker_name.to_lowercase().as_str() {
                                "deepsort" => TrackerType::DeepSort(PersonTracker::new()),
                                "bytetrack" => TrackerType::ByteTrack(ByteTracker::new()),
                                _ => TrackerType::None,
                            };
                        }
                        ControlMessage::TogglePose(enabled) => {
                            self.pose_enabled = enabled;
                            if enabled {
                                if let Some(ref model) = detect_model {
                                    let m = model.lock().unwrap();
                                    if !m.supports_task(YOLOTask::Pose) {
                                        println!("âš ï¸ å½“å‰æ¨¡å‹ä¸æ”¯æŒå§¿æ€ä¼°è®¡,æ— æ³•å¯ç”¨");
                                        self.pose_enabled = false;
                                    } else {
                                        println!("âœ… å§¿æ€ä¼°è®¡å·²å¯ç”¨");
                                    }
                                }
                            } else {
                                println!("ğŸš« å§¿æ€ä¼°è®¡å·²ç¦ç”¨");
                            }
                        }
                        ControlMessage::ToggleDetection(enabled) => {
                            self.detection_enabled = enabled;
                            if enabled {
                                println!("âœ… ç›®æ ‡æ£€æµ‹å·²å¯ç”¨");
                            } else {
                                println!("ğŸš« ç›®æ ‡æ£€æµ‹å·²ç¦ç”¨");
                            }
                        }
                    }
                }
            }

            match rx.recv() {
                Ok(frame) => {
                    // å»¶è¿ŸåŠ è½½: æ”¶åˆ°ç¬¬ä¸€å¸§æ—¶æ‰åŠ è½½æ¨¡å‹
                    if !model_loaded {
                        println!("ğŸ“¥ æ”¶åˆ°ç¬¬ä¸€å¸§æ•°æ®,å¼€å§‹åŠ è½½æ¨¡å‹: {}", self.detect_model_path);
                        match self.load_model(&self.detect_model_path) {
                            Some(model) => {
                                // æ£€æŸ¥å§¿æ€ä¼°è®¡æ”¯æŒ
                                {
                                    let m = model.lock().unwrap();
                                    if self.pose_enabled && !m.supports_task(YOLOTask::Pose) {
                                        println!("âš ï¸ å§¿æ€ä¼°è®¡: å·²è¯·æ±‚ä½†æ¨¡å‹ä¸æ”¯æŒ,å°†ç¦ç”¨");
                                        self.pose_enabled = false;
                                    } else if self.pose_enabled {
                                        println!("âœ… å§¿æ€ä¼°è®¡: å·²å¯ç”¨");
                                    }
                                }
                                detect_model = Some(model);
                                model_loaded = true;
                                println!("âœ… æ¨¡å‹åŠ è½½å®Œæˆ,å¼€å§‹å¤„ç†è§†é¢‘æµ");
                            }
                            None => {
                                eprintln!("âŒ æ¨¡å‹åŠ è½½å¤±è´¥,è·³è¿‡æ­¤å¸§");
                                continue;
                            }
                        }
                    }

                    if self.detection_enabled {
                        if let Some(ref model) = detect_model {
                            self.process_frame(frame, model, inf_size);
                        }
                    } else {
                        // å¦‚æœæ£€æµ‹è¢«ç¦ç”¨ï¼Œä»ç„¶éœ€è¦å‘é€ç©ºç»“æœä»¥ç»´æŒFPSç»Ÿè®¡å’Œç”»é¢æ›´æ–°
                        // æˆ–è€…ç›´æ¥è·³è¿‡å¤„ç†ï¼Œå–å†³äºæ¶æ„è®¾è®¡ã€‚
                        // è¿™é‡Œæˆ‘ä»¬é€‰æ‹©å‘é€ä¸€ä¸ªç©ºçš„æ£€æµ‹ç»“æœï¼Œä»¥ä¾¿æ¸²æŸ“çº¿ç¨‹çŸ¥é“æ²¡æœ‰æ£€æµ‹åˆ°ç‰©ä½“
                        // ä½†ä¸ºäº†èŠ‚çœèµ„æºï¼Œæˆ‘ä»¬ä¸è¿›è¡Œä»»ä½•å›¾åƒå¤„ç†
                        xbus::post(DetectionResult {
                            bboxes: Vec::new(),
                            keypoints: Vec::new(),
                            inference_fps: 0.0,
                            inference_ms: 0.0,
                            tracker_fps: 0.0,
                            tracker_ms: 0.0,
                            resized_image: None,
                            resized_size: inf_size,
                            reid_features: Vec::new(),
                        });
                    }
                }
                Err(e) => {
                    eprintln!("âŒ ç›®æ ‡æ£€æµ‹é˜Ÿåˆ—æ¥æ”¶å¤±è´¥: {}", e);
                    break;
                }
            }

            // TODO: ç›‘å¬SystemControlæ¶ˆæ¯,æ”¯æŒä¼˜é›…é€€å‡º
        }
    }

    /// å¤„ç†å•å¸§æ£€æµ‹ (åœ¨å·¥ä½œçº¿ç¨‹ä¸­æ‰§è¡Œ)
    fn process_frame(
        &mut self,
        frame: DecodedFrame,
        detect_model: &Arc<Mutex<Box<dyn Model>>>,
        inf_size: u32,
    ) {
        let start_total = Instant::now();

        // 2. Resize: åŠ¨æ€åˆ†è¾¨ç‡ â†’ 640x640 (CPUå¹¶è¡Œä¼˜åŒ–)
        let t2 = Instant::now();

        let src_w = frame.width as usize;
        let src_h = frame.height as usize;
        let dst_size = inf_size as usize;
        let src_buffer = &frame.rgba_data;

        // çº¯CPUä¼˜åŒ– (é¿å…GPUæ•°æ®ä¼ è¾“å¼€é”€)
        let rgb_data = Self::cpu_resize_rgba_to_rgb(
            src_buffer,
            src_w,
            src_h,
            dst_size,
            &mut self.resize_x_map,
            &mut self.resize_y_map,
            &mut self.src_width,
            &mut self.src_height,
        );

        let resize_ms = t2.elapsed().as_secs_f64() * 1000.0;

        // 3. RGB â†’ DynamicImage (é›¶æ‹·è´)
        let rgb_img = match RgbImage::from_raw(inf_size, inf_size, rgb_data) {
            Some(img) => img,
            None => {
                eprintln!("âŒ RGBå›¾åƒè½¬æ¢å¤±è´¥");
                return;
            }
        };
        let img = DynamicImage::ImageRgb8(rgb_img);

        // 5. YOLOæ£€æµ‹ (ç»Ÿä¸€å¤„ç†æ‰€æœ‰æ¨¡å‹ç±»å‹)
        let t5_preprocess = Instant::now();

        // æ–¹å¼1: ç»†ç²’åº¦æ§åˆ¶ - åˆ†æ­¥è°ƒç”¨ä»¥ä¾¿è®¡æ—¶
        // æ–¹å¼2: ç®€åŒ–ç‰ˆ - model.forward(&images) (å†…éƒ¨è‡ªåŠ¨è°ƒç”¨ä¸‰æ­¥)
        let images = vec![img]; // åªåˆ›å»ºä¸€æ¬¡Vec,é¿å…é‡å¤clone
        let mut model = detect_model.lock().unwrap();
        let xs = model.preprocess(&images).unwrap_or_default();
        let preprocess_time = t5_preprocess.elapsed().as_secs_f64() * 1000.0;

        let t5_inference = Instant::now();
        let ys = model.run(xs, false).unwrap_or_default();
        let inference_time = t5_inference.elapsed().as_secs_f64() * 1000.0;

        let t5_postprocess = Instant::now();
        let detect_results = model.postprocess(ys, &images).unwrap_or_default();
        let postprocess_time = t5_postprocess.elapsed().as_secs_f64() * 1000.0;
        drop(model);

        let (_preprocess_ms, inference_ms, _postprocess_ms) =
            (preprocess_time, inference_time, postprocess_time);

        // 6. æå–æ£€æµ‹æ¡†å¹¶ç¼©æ”¾åˆ°åŸå§‹åˆ†è¾¨ç‡
        let scale_x = frame.width as f32 / inf_size as f32;
        let scale_y = frame.height as f32 / inf_size as f32;

        let mut bboxes = Vec::new();
        let mut all_detections_count = 0; // è°ƒè¯•: ç»Ÿè®¡æ‰€æœ‰ç±»åˆ«çš„æ£€æµ‹æ•°
        let mut person_detections_count = 0; // è°ƒè¯•: ç»Ÿè®¡äººçš„æ£€æµ‹æ•°

        // COCOç±»åˆ«: 0=person, 39=bottle, 41=cup, 56=chair, 62=tv, 63=laptop, 73=book, 76=scissors
        const DETECT_CLASSES: &[usize] = &[0]; // åªæ£€æµ‹äºº,å¦‚éœ€æ£€æµ‹å…¶ä»–ç±»åˆ«å¯æ·»åŠ : &[0, 39, 41, 56, 62, 63, 73, 76]

        for result in &detect_results {
            if let Some(boxes) = result.bboxes() {
                all_detections_count += boxes.len();
                for bbox in boxes {
                    // æ£€æµ‹æŒ‡å®šç±»åˆ«
                    if DETECT_CLASSES.contains(&bbox.id()) {
                        if bbox.id() == 0 {
                            person_detections_count += 1;
                        }
                        if bbox.confidence() >= 0.01 {
                            bboxes.push(types::BBox {
                                x1: bbox.xmin() * scale_x,
                                y1: bbox.ymin() * scale_y,
                                x2: bbox.xmax() * scale_x,
                                y2: bbox.ymax() * scale_y,
                                confidence: bbox.confidence(),
                                class_id: bbox.id() as u32,
                            });
                        } else if self.count % 30 == 0 && bbox.id() == 0 {
                            eprintln!("âš ï¸ æä½ç½®ä¿¡åº¦äººæ£€æµ‹è¢«è¿‡æ»¤: conf={:.3}", bbox.confidence());
                        }
                    }
                }
            }
        }

        // è°ƒè¯•æ—¥å¿— - ç»Ÿè®¡å„ç±»åˆ«åˆ†å¸ƒ
        if self.count % 30 == 0 && all_detections_count > 0 {
            use std::collections::HashMap;
            let mut class_counts: HashMap<usize, usize> = HashMap::new();
            for result in &detect_results {
                if let Some(boxes) = result.bboxes() {
                    for bbox in boxes {
                        *class_counts.entry(bbox.id()).or_insert(0) += 1;
                    }
                }
            }
            let mut sorted: Vec<_> = class_counts.iter().collect();
            sorted.sort_by(|a, b| b.1.cmp(a.1));
            let top3: Vec<String> = sorted
                .iter()
                .take(3)
                .map(|(k, v)| format!("c{}:{}", k, v))
                .collect();
            eprintln!(
                "ğŸ” åŸå§‹æ£€æµ‹: æ€»{}ä¸ª (top3: {}) | äºº{}ä¸ª | é€šè¿‡é˜ˆå€¼{}ä¸ª",
                all_detections_count,
                top3.join(" "),
                person_detections_count,
                bboxes.len()
            );
        }

        // 7. å§¿æ€ä¼°è®¡
        let mut keypoints = Vec::new();
        if self.pose_enabled {
            for result in &detect_results {
                if let Some(kpts) = result.keypoints() {
                    for kpt in kpts {
                        // è½¬æ¢å…³é”®ç‚¹æ•°æ®: Vec<Point2> -> Vec<(f32, f32, f32)>
                        let points: Vec<(f32, f32, f32)> =
                            kpt.iter().map(|p| (p.x(), p.y(), p.confidence())).collect();
                        keypoints.push(types::PoseKeypoints { points });
                    }
                }
            }
        }

        // 8. è·Ÿè¸ªå™¨æ›´æ–°
        let tracker_start = Instant::now();
        let (tracked_bboxes, reid_features) = match &mut self.tracker {
            TrackerType::DeepSort(tracker) => {
                // ä¼ å…¥åŸå§‹å›¾åƒæ•°æ®ä»¥å¯ç”¨ReIDç‰¹å¾æå–
                // æ³¨æ„: è¿™é‡Œéœ€è¦ä¼ å…¥åŸå§‹å›¾åƒæ•°æ®,æˆ‘ä»¬ç›´æ¥ä½¿ç”¨Arcåˆ‡ç‰‡
                let frame_data = Some((frame.rgba_data.as_slice(), frame.width, frame.height));
                let tracked = tracker.update(&bboxes, &keypoints, frame_data);

                // å°†è·Ÿè¸ªç»“æœè½¬æ¢ä¸ºBBoxæ ¼å¼(ä¿æŒåŸæœ‰ç»“æ„)
                let bboxes: Vec<types::BBox> = tracked
                    .iter()
                    .map(|t| types::BBox {
                        x1: t.bbox.x1,
                        y1: t.bbox.y1,
                        x2: t.bbox.x2,
                        y2: t.bbox.y2,
                        confidence: t.bbox.confidence,
                        class_id: t.id, // ä½¿ç”¨è·Ÿè¸ªIDæ›¿æ¢class_id
                    })
                    .collect();

                // è·å–ReIDç‰¹å¾
                let reid_feats = tracker.get_reid_features();
                (bboxes, reid_feats)
            }
            TrackerType::ByteTrack(tracker) => {
                let tracked = tracker.update(&bboxes);
                let bboxes = tracked
                    .iter()
                    .map(|t| types::BBox {
                        x1: t.bbox.x1,
                        y1: t.bbox.y1,
                        x2: t.bbox.x2,
                        y2: t.bbox.y2,
                        confidence: t.bbox.confidence,
                        class_id: t.id,
                    })
                    .collect();
                (bboxes, Vec::new())
            }
            TrackerType::None => (bboxes.clone(), Vec::new()), // ä¸ä½¿ç”¨è·Ÿè¸ªå™¨,ç›´æ¥è¿”å›æ£€æµ‹ç»“æœ
        };
        let tracker_ms = tracker_start.elapsed().as_secs_f64() * 1000.0;

        // æ›´æ–°è·Ÿè¸ªå™¨ç»Ÿè®¡
        if !matches!(self.tracker, TrackerType::None) {
            self.tracker_count += 1;
            let now_tracker = Instant::now();
            if now_tracker.duration_since(self.tracker_last).as_secs() >= 1 {
                self.tracker_current_fps = self.tracker_count as f64
                    / now_tracker.duration_since(self.tracker_last).as_secs_f64();
                self.tracker_count = 0;
                self.tracker_last = now_tracker;
            }
        }

        // ä½¿ç”¨è·Ÿè¸ªåçš„ç»“æœæ›¿æ¢åŸå§‹æ£€æµ‹æ¡†
        let bboxes = tracked_bboxes;

        // 9. æ›´æ–°ç»Ÿè®¡
        self.count += 1;
        let now = Instant::now();
        if now.duration_since(self.last).as_secs() >= 1 {
            self.current_fps = self.count as f64 / now.duration_since(self.last).as_secs_f64();
            self.count = 0;
            self.last = now;
        }

        // è®¡ç®—æ€»è€—æ—¶ (ç§»é™¤æœªä½¿ç”¨çš„tracker_mså˜é‡)
        let total_ms = start_total.elapsed().as_secs_f64() * 1000.0;

        // æ€§èƒ½ç›‘æ§æ—¥å¿— (æ¯60å¸§æ‰“å°ä¸€æ¬¡ç®€æ´ä¿¡æ¯)
        if self.count % 60 == 0 {
            if matches!(self.tracker, TrackerType::None) {
                eprintln!(
                    "ğŸ¯ æ£€æµ‹: {}äºº | {:.1}ms/å¸§ | {:.1}fps (Resize:{:.1}ms | æ¨ç†:{:.1}ms)",
                    bboxes.len(),
                    total_ms,
                    self.current_fps,
                    resize_ms,
                    inference_ms
                );
            } else {
                eprintln!(
                    "ğŸ¯ æ£€æµ‹+è·Ÿè¸ª: {}äºº | {:.1}ms/å¸§ | {:.1}fps (Resize:{:.1}ms | æ¨ç†:{:.1}ms | è·Ÿè¸ª:{:.1}ms)",
                    bboxes.len(),
                    total_ms,
                    self.current_fps,
                    resize_ms,
                    inference_ms,
                    tracker_ms
                );
            }
        }

        // 10. å‘é€æ£€æµ‹ç»“æœåˆ°XBus
        // ç§»é™¤ resized_image ä»¥èŠ‚çœå†…å­˜ (æ¯å¸§ 640x640x4 = 1.6MB)
        xbus::post(DetectionResult {
            bboxes,
            keypoints,
            inference_fps: self.current_fps,
            inference_ms,
            tracker_fps: self.tracker_current_fps,
            tracker_ms,
            resized_image: None, // ä¸å†ä¼ è¾“é¢„è§ˆå›¾åƒ,èŠ‚çœå†…å­˜
            resized_size: inf_size,
            reid_features,
        });
    }
}
